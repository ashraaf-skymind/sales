{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Technology Sales Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# pip install this package to view the summary of model  \n",
    "# used jupyter install due to it does not have conda version\n",
    "# %%capture suppress information of torchsummaryX installation\n",
    "!pip install torchsummaryX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import statsmodels as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used is the Superstore sales data, which contains several categories. For this project, we are focusing on forecasting the technology sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../Dataset/superstore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7012deabf8e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Import data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../Dataset/superstore.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\time-series-labs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\time-series-labs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\time-series-labs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\time-series-labs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\time-series-labs\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../Dataset/superstore.csv'"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "df = pd.read_csv(\"../../Dataset/superstore.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get technology categories\n",
    "technology = df.loc[df['Category'] == 'Technology']\n",
    "technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n",
    "Remove unnecessary columns, check missing values, aggregate sales by date, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unnecessary columns, only need order date and sales data\n",
    "cols = ['Row ID', 'Order ID', 'Ship Date', 'Ship Mode', 'Customer ID', 'Customer Name', 'Segment', 'Country', 'City', 'State', 'Postal Code', 'Region', 'Product ID', 'Category', 'Sub-Category', 'Product Name', 'Quantity', 'Discount', 'Profit']\n",
    "technology.drop(cols, axis=1, inplace=True)\n",
    "technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort list based on Order Date by ascending order \n",
    "technology = technology.sort_values('Order Date')\n",
    "technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values\n",
    "technology.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Accumulates total sales with those that have same order date\n",
    "technology = technology.groupby('Order Date')['Sales'].sum().reset_index()\n",
    "technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change default index to be time series data index\n",
    "technology['Order Date'] = pd.to_datetime(technology['Order Date'])\n",
    "technology.set_index('Order Date', inplace=True)\n",
    "technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will use average daily sales value for each month. The start of each month as the timestamp\n",
    "y = technology['Sales'].resample('MS').mean()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing technology dales time series data\n",
    "#Generate graph\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.grid()\n",
    "plt.plot(y)\n",
    "plt.title('Technology Sales')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decomposition = sm.tsa.seasonal_decompose(y, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot ACF\n",
    "#plot_acf(y, lags=range(1,12), alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot PACF\n",
    "#plot_pacf(y, lags=range(1,12), alpha=0.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for stationarity using ADF test\n",
    "def print_adf_result(adf_result):\n",
    "    df_results = pd.Series(adf_result[0:4], index=['ADF Test Statistic','P-Value','# Lags Used','# Observations Used'])\n",
    "    \n",
    "    for key, value in adf_result[4].items():\n",
    "        df_results['Critical Value (%s)'% key] = value\n",
    "    print('Augmented Dickey-Fuller Test Results:')\n",
    "    print(df_results)\n",
    "    \n",
    "\n",
    "result = adfuller(y, maxlag=12)\n",
    "print_adf_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "1st = SARIMA model,\n",
    "2nd = LSTM model,\n",
    "3rd = CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st: SARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SARIMA\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax = SARIMAX(y, order=(0,1,1), seasonal_order=(0,1,1,12)).fit()\n",
    "sarimax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sarimax.plot_diagnostics(figsize=(20, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals =pd.Series(sarimax.resid)\n",
    "def check_residuals(series):\n",
    "    fig = plt.figure(figsize=(20, 10))    \n",
    "    gs = fig.add_gridspec(2,2)\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(series)\n",
    "    ax1.set_title('residuals')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[1,0])\n",
    "    plot_acf(series, ax=ax2, title='ACF')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[1,1])\n",
    "    sns.kdeplot(series, ax=ax3)\n",
    "    ax3.set_title('density')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "check_residuals(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Compare forecast data and observed data with SARIMA\n",
    "pred = results.get_prediction(start=pd.to_datetime('2017-01-01'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "ax = y['2014':].plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=0.2)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Technology Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forecasted = pred.predicted_mean\n",
    "y_truth = y['2017-01-01':]\n",
    "mse = ((y_forecasted - y_truth) ** 2).mean()\n",
    "#print('The Mean Squared Error of our forecasts is {}'.format(round(mse, 2)))\n",
    "print('The Root Mean Squared Error of our forecasts is {}'.format(round(np.sqrt(mse), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecast sales for future years\n",
    "sarimax_forecast = sarimax.get_forecast(48)\n",
    "sarimax_forecast_conf_int = sarimax_forecast.conf_int()\n",
    "\n",
    "plt.plot(y, label='observed')\n",
    "plt.plot(sarimax_forecast.predicted_mean, label='forecast')\n",
    "\n",
    "\n",
    "plt.fill_between(sarimax_forecast_conf_int.index,\n",
    "                 sarimax_forecast_conf_int.iloc[:, 0],\n",
    "                 sarimax_forecast_conf_int.iloc[:, 1], color='k', alpha=.2)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd: LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "import math\n",
    "from matplotlib.lines import Line2D\n",
    "from torchsummaryX import summary\n",
    "\n",
    "# To auto load the customise module\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import deep_learning_module\n",
    "import data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set hyperparameters\n",
    "num_epochs = 100\n",
    "split_ratio = 0.70\n",
    "batch_size = 2\n",
    "window_size = 2\n",
    "n_step = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data by indexing\n",
    "split_data = round(len(y)*split_ratio)\n",
    "split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data spliting\n",
    "train_data = y[:split_data]\n",
    "test_data = y[split_data:]\n",
    "train_time = train_data.index\n",
    "test_time = test_data.index\n",
    "print(\"train_data_shape\")\n",
    "print(train_data.shape)\n",
    "print(\"test_data_shape\")\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data standardization\n",
    "scaler = StandardScaler().fit(train_data.values.reshape(-1,1))\n",
    "scaler_train_data = scaler.transform(train_data.values.reshape(-1,1))\n",
    "scaler_test_data = scaler.transform(test_data.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"scaler_train_data shape : {scaler_train_data.shape}\")\n",
    "print(f\"scaler_test_data shape : {scaler_test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sequencing\n",
    "trainX ,trainY =  data_module.univariate_multi_step(scaler_train_data,window_size,n_step)\n",
    "testX , testY = data_module.univariate_multi_step(scaler_test_data,window_size,n_step)\n",
    "\n",
    "print(f\"trainX shape:{trainX.shape} trainY shape:{trainY.shape}\")\n",
    "print(f\"testX shape:{testX.shape} testX shape:{testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_assign(trainingX,testingX,trainingY,testingY):\n",
    "    \"\"\" \n",
    "    Use to assign  the key to create the train_data_dict and test_data_dict   \n",
    "    Arguments:\n",
    "    trainingX -- feature for traning data \n",
    "    testingX -- feature for testing data\n",
    "    trainingY -- label for traning data\n",
    "    testingY -- label for testing data   \n",
    "    Returns: \n",
    "    train_data_dict -- dictionary of trainingX and trainingY\n",
    "    test_data_dict -- dictionary of testingX and testingY\n",
    "    \"\"\"    \n",
    "    # Create a dictionary that can store the train set feature and label\n",
    "    train_data_dict = {\"train_data_x_feature\" : trainingX, \"train_data_y_label\" : trainingY}\n",
    "    \n",
    "    # Create a dictionary that can store the test set feature and label\n",
    "    test_data_dict  = {\"test_data_x_feature\" : testingX , \"test_data_y_label\" : testingY }\n",
    "\n",
    "    return train_data_dict , test_data_dict\n",
    "\n",
    "train_data_dictionary , test_data_dictionary = key_assign(trainingX = trainX,\n",
    "                                 testingX = testX,\n",
    "                                 trainingY = trainY,\n",
    "                                 testingY = testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(train_data_dict, test_data_dict):\n",
    "    \"\"\" \n",
    "    Transform the NumPy data to torch tensor    \n",
    "    Arguments:\n",
    "    train_data_dict -- train data dictionary \n",
    "    test_data_dict -- test data dictionary    \n",
    "    Returns: \n",
    "    train_data_dict -- train data dictionary \n",
    "    test_data_dict -- test data dictionary\n",
    "    \"\"\"\n",
    "    for train_datapoint in train_data_dict:\n",
    "        train_data_dict[train_datapoint] =  torch.from_numpy(train_data_dict[train_datapoint]).type(torch.Tensor)\n",
    "        \n",
    "    for test_datapoint in test_data_dict:\n",
    "        test_data_dict[test_datapoint] = torch.from_numpy(test_data_dict[test_datapoint]).type(torch.Tensor)\n",
    "\n",
    "    return train_data_dict,test_data_dict\n",
    "\n",
    "train_data_dictionary,test_data_dictionary = transform(train_data_dictionary,test_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(data_1,data_2):\n",
    "    \"\"\" \n",
    "    Print the shape of data_1 and data_2    \n",
    "    Arguments:\n",
    "    data_1 -- (dict) type of data\n",
    "    data_2 -- (dict) type of data \n",
    "    \"\"\"\n",
    "    for key_1 in data_1:\n",
    "        print(key_1 +\" shape : \" + str(data_1[key_1].shape))\n",
    "    for key_2 in data_2:\n",
    "        print(key_2 +\" shape : \" + str(data_2[key_2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check\n",
    "sanity_check(train_data_dictionary,test_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Iterator\n",
    "def iterator(train_data_dict,test_data_dict,batch_size):\n",
    "    \"\"\" \n",
    "    Create iterator for train data and test data     \n",
    "    Arguments:\n",
    "    train_data_dict -- train data dictionary \n",
    "    test_data_dict -- test data dictionary    \n",
    "    Returns: \n",
    "    train_iter -- train data iterator \n",
    "    test_iter -- test data iterator \n",
    "    \"\"\"\n",
    "    train_dataset = TensorDataset(train_data_dict[\"train_data_x_feature\" ],\n",
    "                                  train_data_dict[\"train_data_y_label\"])\n",
    "    train_iter = DataLoader(train_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    test_dataset = TensorDataset(test_data_dict[\"test_data_x_feature\"],\n",
    "                                 test_data_dict[\"test_data_y_label\"])\n",
    "    test_iter = DataLoader(test_dataset,batch_size=batch_size,shuffle=False)\n",
    "    \n",
    "    return train_iter , test_iter\n",
    "\n",
    "train_iter , test_iter = iterator(train_data_dictionary,test_data_dictionary,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Configuration\n",
    "# seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#Arguments for LSTM model\n",
    "hidden_dim = 1\n",
    "n_feature = 1 \n",
    "\n",
    "#1 for vanila LSTM , >1 is mean stacked LSTM\n",
    "num_layers = 1 \n",
    "\n",
    "#Vanila , Stacked LSTM\n",
    "model = deep_learning_module.LSTM(n_feature = n_feature ,\n",
    "                         hidden_dim = hidden_dim ,\n",
    "                         num_layers = num_layers,\n",
    "                         n_step = n_step)\n",
    "#loss function \n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#optimiser\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.zeros((batch_size,window_size,1),dtype=torch.float) # batch size , seq_length , input_dim\n",
    "print(summary(model,inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start Training \n",
    "torch.manual_seed(123)\n",
    "train_loss,val_loss = deep_learning_module.training(num_epochs,train_iter,test_iter,optimizer,loss_fn,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.learning_curve(num_epochs,train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module.zoom_learning_curve(start_epoch = 50,\n",
    "                                end_epoch =60 ,\n",
    "                                training_loss = train_loss,\n",
    "                                validation_loss = val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "#Section 1 : Feed in the train and test data to the model\n",
    "with torch.no_grad():\n",
    "    y_train_prediction = model(train_data_dictionary[\"train_data_x_feature\"])\n",
    "    y_test_prediction = model(test_data_dictionary[\"test_data_x_feature\"])\n",
    "    \n",
    "def key_assign_evaluation(y_train_prediction,\n",
    "                          y_test_prediction,\n",
    "                          train_data_dictionary,\n",
    "                          test_data_dictionary):\n",
    "    \"\"\" \n",
    "    Assign key for prediction and output data dictionary     \n",
    "    Arguments:\n",
    "    y_train_prediction -- (tensor) prediction for training data\n",
    "    y_test_prediction -- (tensor) prediction for test data\n",
    "    train_data_dictionary -- (dict) train data dictionary\n",
    "    test_data_dictionary -- (dict) test data dictionary        \n",
    "    Returns: \n",
    "    prediction -- (dict) dictionary that consists of prediction from train data and test data\n",
    "    output_data -- (dict) dictionary that consists of output(label) from train data and test data\n",
    "    \"\"\"\n",
    "    prediction ={\"train_data_prediction\" : y_train_prediction,\n",
    "            \"test_data_prediction\" :y_test_prediction }\n",
    "    output_data ={\"train_data_output\" : train_data_dictionary[\"train_data_y_label\"] ,\n",
    "               \"test_data_output\" : test_data_dictionary[\"test_data_y_label\"]}\n",
    "    \n",
    "    return prediction , output_data\n",
    "\n",
    "prediction , output_data = key_assign_evaluation(y_train_prediction,y_test_prediction,\n",
    "                                                 train_data_dictionary,\n",
    "                                                 test_data_dictionary)     \n",
    "\n",
    "#Check the prediction and output shape\n",
    "sanity_check(data_1 = prediction,data_2 = output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 2 : Reshape both to the original data dimension\n",
    "def squeeze_dimension(output):\n",
    "    \"\"\" \n",
    "    Squeeze the dimension of output data    \n",
    "    Arguments:\n",
    "    output -- (dict) output_data    \n",
    "    Returns: \n",
    "    output_data -- (dict) output_data\n",
    "    \"\"\"\n",
    "    for key in output:\n",
    "        output[key] = torch.squeeze(output[key],2)\n",
    "\n",
    "    return output\n",
    "\n",
    "output_data = squeeze_dimension(output_data)\n",
    "\n",
    "#Check the output shape\n",
    "sanity_check(data_1 = output_data,data_2 = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 3 : Invert the scaling back to orignal data value\n",
    "def inverse_scaler(scaled_data,scaler):\n",
    "    \"\"\" \n",
    "    Inverse the scaled data    \n",
    "    Arguments:\n",
    "    scaled_data -- (dict) data that being scaled \n",
    "    scaler -- scaler     \n",
    "    Returns: \n",
    "    scaled_data -- (dict) data after inverse scale\n",
    "    \"\"\"\n",
    "    for item in scaled_data:\n",
    "        scaled_data[item] =  scaler.inverse_transform(scaled_data[item].detach().numpy())\n",
    "\n",
    "    return scaled_data\n",
    "    \n",
    "prediction = inverse_scaler(prediction,scaler)\n",
    "output_data  = inverse_scaler(output_data ,scaler)\n",
    "\n",
    "sanity_check(data_1 = prediction,data_2 = output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_forecast_value(output_data,prediction):\n",
    "    \"\"\" \n",
    "    To list the test output and prediction output side by side    \n",
    "    Arguments:\n",
    "    output_data --  (dict) output data dictionary\n",
    "    prediction -- (dict) prediction output dictionary\n",
    "    \"\"\"\n",
    "    print(\"Test Data\\t\\t\\tForecast\")\n",
    "    for test, forecast in zip(output_data[\"test_data_output\"],prediction[\"test_data_prediction\"]):   \n",
    "        print(f\"{test}\\t\\t{forecast}\")\n",
    "        \n",
    "list_forecast_value(output_data,prediction)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 4 : Calculate the RMSE of train and test data\n",
    "def rmse(prediction,output_data):\n",
    "    \"\"\" \n",
    "    Calculate RMSE between output data and prediction data     \n",
    "    Arguments:\n",
    "    prediction -- (dict) prediction output dictionary\n",
    "    output_data --  (dict) output data dictionary    \n",
    "    Returns:\n",
    "    trainScore - RMSE of train dataset\n",
    "    testScore - RMSE of test dataset\n",
    "    \"\"\"\n",
    "    trainScore = math.sqrt(mean_squared_error(prediction[\"train_data_prediction\"], output_data[\"train_data_output\"]))\n",
    "    testScore = math.sqrt(mean_squared_error(prediction[\"test_data_prediction\"], output_data[\"test_data_output\"]))\n",
    "    return trainScore,testScore\n",
    "\n",
    "trainScore,testScore = rmse(prediction,output_data)\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_details ={\"x-axis\" : \"Order Date\",\n",
    "          \"y-axis\" : \"Sales\",\n",
    "          \"title\"  : \"Technology Sales\"\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast plot for multi-step\n",
    "def multi_step_plot(original_test_data,\n",
    "                    after_sequence_test_data ,\n",
    "                    forecast_data,test_time,window_size,\n",
    "                    n_step ,\n",
    "                    details = {},\n",
    "                    original_plot = False):\n",
    "    \n",
    "    \"\"\" \n",
    "    Plot the result of the multi-step forecast    \n",
    "    Arguments:    \n",
    "    original_test_data -- test data before sequence    \n",
    "    after_sequence_test_data -- (dict) output data dictionary   \n",
    "    forecast_data -- (dict) prediction data dictionary    \n",
    "    test_time --  time index for test data before sliding window (data sequence)    \n",
    "    window_size -- window size for the data sequence    \n",
    "    n_step -- the number of future step , 1 -> single >1 -> multi-step    \n",
    "    details -- (dict) details for plot such as \"x-axis\" ,\"y-axis\", \"title\"    \n",
    "    original_plot -- (boolean) True ->observe how sliding window (data sequence) take place in the test data    \n",
    "    \"\"\"\n",
    "    \n",
    "    after_sequence_test_data = after_sequence_test_data['test_data_output'] \n",
    "    forecast_data = forecast_data[\"test_data_prediction\"]\n",
    "    \n",
    "    # Plot Setting\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.xticks(rotation=45)    \n",
    "    \n",
    "    # Store test and forecast data into DataFrame type \n",
    "    column_names = [\"timestep_\" + str(i) for i in range(after_sequence_test_data.shape[1])]\n",
    "    y_test_dataframe = pd.DataFrame(after_sequence_test_data,columns = column_names)\n",
    "    y_test_pred_dataframe =pd.DataFrame(forecast_data,columns = column_names)\n",
    "    \n",
    "    # Create time index for data after sequence\n",
    "    time_index_after_sequence = test_time[window_size:]\n",
    "    \n",
    "    # Test Data plot before sliding window(data sequencing)\n",
    "    if original_plot:\n",
    "        plt.plot(test_time,original_test_data,marker='x',color=\"blue\")\n",
    "\n",
    "    # For loop to plot the data step by step base on time index    \n",
    "    start_idx = 0 \n",
    "    for row in range(len(y_test_dataframe)):\n",
    "        \n",
    "        # Iterate the time index after sequence\n",
    "        time_index = time_index_after_sequence[start_idx:start_idx+n_step]\n",
    "        \n",
    "        # Plot the test data\n",
    "        plt.plot(time_index,y_test_dataframe.iloc[row],color=\"green\",marker='o')\n",
    "        \n",
    "        # Plot the forecast data\n",
    "        plt.plot(time_index,y_test_pred_dataframe.iloc[row],color=\"red\",marker='o')\n",
    "        \n",
    "        # Pointer for time_index_after_sequence\n",
    "        start_idx += 1\n",
    "        \n",
    "    # Customize the legend\n",
    "    custom_lines = [Line2D([0], [0], color=\"green\", lw=4),\n",
    "                Line2D([0], [0], color=\"red\", lw=4),\n",
    "                Line2D([0], [0], color=\"blue\", lw=4)]\n",
    "    plt.legend(custom_lines, ['Test Data After Sequencing', 'Forecast Data', 'Test Data Before Sequencing'])\n",
    "    \n",
    "    # Extra details - Optional function\n",
    "    if details != {}:\n",
    "        plt.xlabel(details[\"x-axis\"])\n",
    "        plt.ylabel(details[\"y-axis\"])\n",
    "        plt.title(details[\"title\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the multi_step_plot function\n",
    "multi_step_plot(original_test_data = test_data,\n",
    "                after_sequence_test_data = output_data ,\n",
    "                forecast_data = prediction,\n",
    "                test_time = test_time,\n",
    "                window_size = window_size ,\n",
    "                n_step = n_step,\n",
    "                details = plot_details,\n",
    "                original_plot = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd: CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.dates as mdates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter/Data spliting/Data Standardization - mostly reuse form lstm model\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transform\n",
    "train_data_dictionary ,test_data_dictionary = data_module.key_assign(trainingX = trainX  , \n",
    "                       testingX = testX, \n",
    "                       trainingY = trainY, \n",
    "                       testingY = testY)\n",
    "\n",
    "train_data_dictionary ,test_data_dictionary = data_module.transform(train_data_dictionary ,test_data_dictionary)\n",
    "\n",
    "#Sanity check\n",
    "data_module.sanity_check(train_data_dictionary , test_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Transpose\n",
    "train_data_dictionary , test_data_dictionary = data_module.transpose(train_data_dictionary, test_data_dictionary)\n",
    "\n",
    "#Sanity check\n",
    "data_module.sanity_check(train_data_dictionary , test_data_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Iterator\n",
    "train_iter , test_iter = data_module.iterator(train_data_dictionary,\n",
    "                                              test_data_dictionary,\n",
    "                                              batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN configuration\n",
    "# seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "n_feature = train_data_dictionary['train_data_x_feature'].shape[1]\n",
    "\n",
    "# Input the attribute need by the model \n",
    "model = deep_learning_module.CNN(n_feature = n_feature,\n",
    "                        n_step = n_step )\n",
    "\n",
    "# Define the optimizer (Here we use Adam as our optimizer)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function (Here we use MSE as the loss function)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = train_data_dictionary['train_data_x_feature'].shape[2]\n",
    "\n",
    "# batch size ,input_dim ,seq_length\n",
    "inputs = torch.zeros((batch_size,\n",
    "                      n_feature,\n",
    "                      seq_length),dtype=torch.float) \n",
    "\n",
    "print(summary(model,inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#  Xavier Weight Initialize \n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        \n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "# seed\n",
    "torch.manual_seed(123)\n",
    "# Start Training\n",
    "train_loss, val_loss = deep_learning_module.training(num_epochs, train_iter, test_iter, optimizer, loss_fn, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "data_module.learning_curve(num_epochs = num_epochs , train_loss = train_loss , val_loss = val_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "# Section 1 : make predictions\n",
    "with torch.no_grad():\n",
    "    y_train_prediction = model(train_data_dictionary['train_data_x_feature'])\n",
    "    y_test_prediction = model(test_data_dictionary['test_data_x_feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign evaluation key\n",
    "\n",
    "prediction , output = data_module.key_assign_evaluation(y_train_prediction,\n",
    "                                                        y_test_prediction,\n",
    "                                                        train_data_dictionary,\n",
    "                                                        test_data_dictionary)\n",
    "# Section 2 : Reshape to original data\n",
    "# Squeeze the output dimension\n",
    "output_data = data_module.squeeze_dimension(output)\n",
    "\n",
    "#sanity check\n",
    "data_module.sanity_check(data_1 = output_data,data_2 = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 : Invert the scaling back to the original data value\n",
    "prediction = data_module.inverse_scaler(prediction,scaler)\n",
    "output_data  = data_module.inverse_scaler(output_data ,scaler)\n",
    "\n",
    "#sanity check\n",
    "data_module.sanity_check(data_1 = prediction,data_2 = output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the forecast value\n",
    "data_module.list_forecast_value(output_data,prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 4 : Calculate the RMSE of train and test data\n",
    "trainScore,testScore = data_module.rmse(prediction,output_data)\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot forecast graph\n",
    "plot_details ={\"x-axis\" : \"Order Date\",\n",
    "          \"y-axis\" : \"Sales\",\n",
    "          \"title\"  : \"Technology Sales\"\n",
    "         }\n",
    "# Use the multi_step_plot function\n",
    "data_module.multi_step_plot(original_test_data = test_data,\n",
    "                after_sequence_test_data = output_data ,\n",
    "                forecast_data = prediction,\n",
    "                test_time = test_time,\n",
    "                window_size = window_size ,\n",
    "                n_step = n_step,\n",
    "                details = plot_details,\n",
    "                original_plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
